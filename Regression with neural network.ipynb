{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsGgD2wC0oaI"
      },
      "outputs": [],
      "source": [
        "#Neural network with 1 input layer, 2 hidden layer and 1 output layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "z4bSq1lnGR-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating random X values and y values(with noise)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "X =np.random.rand(100, 2)\n",
        "matrix= np.array([[2], [3]])\n",
        "y = X @ matrix + np.random.randn(100, 1) * 0.1"
      ],
      "metadata": {
        "id": "Hd2qog_C0tQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#neurons_in_each_layer\n",
        "input_neuron=2\n",
        "hl1_neuron=5\n",
        "hl2_neuron=5\n",
        "output_neuron=1"
      ],
      "metadata": {
        "id": "MIrqXU_K1MCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#weights and biases initialization\n",
        "\n",
        "#i/p to hidden layer1\n",
        "w1 = np.random.randn(input_neuron,hl1_neuron) *0.01\n",
        "b1 = np.zeros((1,hl1_neuron))\n",
        "\n",
        "#hidden layer 1 to hidden layer 2\n",
        "w2=np.random.randn(hl1_neuron,hl2_neuron) *0.01\n",
        "b2= np.zeros((1,hl2_neuron))\n",
        "\n",
        "#hidden layer2 to output layer\n",
        "w3=np.random.randn(hl2_neuron,output_neuron) *0.01\n",
        "b3 = np.zeros((1,output_neuron))\n"
      ],
      "metadata": {
        "id": "dGd-dXYTJjmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameter_initialization\n",
        "learning_rate=0.001\n",
        "\n",
        "\n",
        "#relu_activation\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n"
      ],
      "metadata": {
        "id": "t3GJJuE0JnZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forward_propagation_with_relu_activation_function\n",
        "def forward_prop(X, w1, b1, w2, b2, w3, b3):\n",
        "    Z1 = np.dot(X, w1) + b1\n",
        "    A1 = relu(Z1)\n",
        "\n",
        "    Z2 = np.dot(A1, w2) + b2\n",
        "    A2 = relu(Z2)\n",
        "\n",
        "    y_pred = np.dot(A2, w3) + b3\n",
        "    return y_pred, A1, A2"
      ],
      "metadata": {
        "id": "RS4wfJLx2qsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cost_computation_MSE\n",
        "def cost_func(y,y_pred):\n",
        "  return np.mean((y-y_pred)**2)"
      ],
      "metadata": {
        "id": "fabBap0m3pBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-Bi6KmTamQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#backpropagation_to_compute_gradients\n",
        "def back_prop(X,y,y_pred,A1,A2,w1,w2,w3):\n",
        "\n",
        "    # Output layer gradients\n",
        "    dy_pred = (-2 / len(y)) * (y - y_pred)  # Gradient of loss w.r.t. y_pred\n",
        "    dw3 = np.dot(A2.T, dy_pred)  # Gradient of loss w.r.t. w3\n",
        "    db3 = np.sum(dy_pred, axis=0, keepdims=True)  # Gradient of loss w.r.t. b3\n",
        "\n",
        "    # Hidden layer 2 gradients\n",
        "    dA2 = np.dot(dy_pred, w3.T)\n",
        "    dZ2 = dA2 * (A2 > 0)  # Derivative of ReLU\n",
        "    dw2 = np.dot(A1.T, dZ2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    # Hidden layer 1 gradients\n",
        "    dA1 = np.dot(dZ2, w2.T)\n",
        "    dZ1 = dA1 * (A1 > 0)  # Derivative of ReLU\n",
        "    dw1 = np.dot(X.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    return dw1,db1,dw2,db2,dw3,db3"
      ],
      "metadata": {
        "id": "nG0oOo3A4ZlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "71M0hqNb8aTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w1, b1, w2, b2, w3, b3, learning_rate, iteration_list):\n",
        "    final_cost = None\n",
        "\n",
        "    for iteration in iteration_list:\n",
        "        print(f\"\\nFor {iteration} iterations:\")\n",
        "        for i in range(iteration):\n",
        "            y_pred, A1, A2 = forward_prop(X, w1, b1, w2, b2, w3, b3)\n",
        "\n",
        "            # Computing cost\n",
        "            cost = cost_func(y, y_pred)\n",
        "\n",
        "            # Backward pass\n",
        "            dw1, db1, dw2, db2, dw3, db3 = back_prop(X, y, y_pred, A1, A2, w1, w2, w3)\n",
        "\n",
        "            # Updating weights and biases\n",
        "            w1 -= learning_rate * dw1\n",
        "            b1 -= learning_rate * db1\n",
        "            w2 -= learning_rate * dw2\n",
        "            b2 -= learning_rate * db2\n",
        "            w3 -= learning_rate * dw3\n",
        "            b3 -= learning_rate * db3\n",
        "\n",
        "            # Print cost for every 100 iterations\n",
        "            if i % 100 == 0:\n",
        "                print(f\"  Iteration {i}: Cost = {cost:.4f}\")\n",
        "\n",
        "        # cost for current iteration\n",
        "        final_cost = cost\n",
        "\n",
        "\n",
        "    return w1, b1, w2, b2, w3, b3, final_cost\n",
        "\n",
        "#iteration list\n",
        "iterations_list = [200, 400, 800,2000,5000,6000,7000,8000,9000]\n",
        "\n",
        "#costs for different iterations\n",
        "w1, b1, w2, b2, w3, b3, last_cost = gradient_descent(X, y, w1, b1, w2, b2, w3, b3, learning_rate, iterations_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPjLGPvPKnHR",
        "outputId": "5ac274e1-1dd9-4296-cfe1-1eae90fa891e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For 200 iterations:\n",
            "  Iteration 0: Cost = 7.0182\n",
            "  Iteration 100: Cost = 5.0637\n",
            "\n",
            "For 400 iterations:\n",
            "  Iteration 0: Cost = 3.7541\n",
            "  Iteration 100: Cost = 2.8766\n",
            "  Iteration 200: Cost = 2.2887\n",
            "  Iteration 300: Cost = 1.8947\n",
            "\n",
            "For 800 iterations:\n",
            "  Iteration 0: Cost = 1.6307\n",
            "  Iteration 100: Cost = 1.4538\n",
            "  Iteration 200: Cost = 1.3353\n",
            "  Iteration 300: Cost = 1.2559\n",
            "  Iteration 400: Cost = 1.2027\n",
            "  Iteration 500: Cost = 1.1671\n",
            "  Iteration 600: Cost = 1.1432\n",
            "  Iteration 700: Cost = 1.1272\n",
            "\n",
            "For 2000 iterations:\n",
            "  Iteration 0: Cost = 1.1165\n",
            "  Iteration 100: Cost = 1.1093\n",
            "  Iteration 200: Cost = 1.1045\n",
            "  Iteration 300: Cost = 1.1013\n",
            "  Iteration 400: Cost = 1.0992\n",
            "  Iteration 500: Cost = 1.0977\n",
            "  Iteration 600: Cost = 1.0968\n",
            "  Iteration 700: Cost = 1.0961\n",
            "  Iteration 800: Cost = 1.0957\n",
            "  Iteration 900: Cost = 1.0954\n",
            "  Iteration 1000: Cost = 1.0952\n",
            "  Iteration 1100: Cost = 1.0951\n",
            "  Iteration 1200: Cost = 1.0950\n",
            "  Iteration 1300: Cost = 1.0949\n",
            "  Iteration 1400: Cost = 1.0949\n",
            "  Iteration 1500: Cost = 1.0949\n",
            "  Iteration 1600: Cost = 1.0948\n",
            "  Iteration 1700: Cost = 1.0948\n",
            "  Iteration 1800: Cost = 1.0948\n",
            "  Iteration 1900: Cost = 1.0948\n",
            "\n",
            "For 5000 iterations:\n",
            "  Iteration 0: Cost = 1.0948\n",
            "  Iteration 100: Cost = 1.0948\n",
            "  Iteration 200: Cost = 1.0948\n",
            "  Iteration 300: Cost = 1.0948\n",
            "  Iteration 400: Cost = 1.0948\n",
            "  Iteration 500: Cost = 1.0948\n",
            "  Iteration 600: Cost = 1.0948\n",
            "  Iteration 700: Cost = 1.0948\n",
            "  Iteration 800: Cost = 1.0948\n",
            "  Iteration 900: Cost = 1.0948\n",
            "  Iteration 1000: Cost = 1.0948\n",
            "  Iteration 1100: Cost = 1.0948\n",
            "  Iteration 1200: Cost = 1.0948\n",
            "  Iteration 1300: Cost = 1.0948\n",
            "  Iteration 1400: Cost = 1.0948\n",
            "  Iteration 1500: Cost = 1.0948\n",
            "  Iteration 1600: Cost = 1.0948\n",
            "  Iteration 1700: Cost = 1.0948\n",
            "  Iteration 1800: Cost = 1.0948\n",
            "  Iteration 1900: Cost = 1.0948\n",
            "  Iteration 2000: Cost = 1.0948\n",
            "  Iteration 2100: Cost = 1.0948\n",
            "  Iteration 2200: Cost = 1.0948\n",
            "  Iteration 2300: Cost = 1.0948\n",
            "  Iteration 2400: Cost = 1.0948\n",
            "  Iteration 2500: Cost = 1.0948\n",
            "  Iteration 2600: Cost = 1.0948\n",
            "  Iteration 2700: Cost = 1.0948\n",
            "  Iteration 2800: Cost = 1.0948\n",
            "  Iteration 2900: Cost = 1.0948\n",
            "  Iteration 3000: Cost = 1.0948\n",
            "  Iteration 3100: Cost = 1.0948\n",
            "  Iteration 3200: Cost = 1.0948\n",
            "  Iteration 3300: Cost = 1.0948\n",
            "  Iteration 3400: Cost = 1.0948\n",
            "  Iteration 3500: Cost = 1.0948\n",
            "  Iteration 3600: Cost = 1.0948\n",
            "  Iteration 3700: Cost = 1.0948\n",
            "  Iteration 3800: Cost = 1.0948\n",
            "  Iteration 3900: Cost = 1.0948\n",
            "  Iteration 4000: Cost = 1.0948\n",
            "  Iteration 4100: Cost = 1.0948\n",
            "  Iteration 4200: Cost = 1.0948\n",
            "  Iteration 4300: Cost = 1.0948\n",
            "  Iteration 4400: Cost = 1.0948\n",
            "  Iteration 4500: Cost = 1.0948\n",
            "  Iteration 4600: Cost = 1.0948\n",
            "  Iteration 4700: Cost = 1.0948\n",
            "  Iteration 4800: Cost = 1.0948\n",
            "  Iteration 4900: Cost = 1.0948\n",
            "\n",
            "For 6000 iterations:\n",
            "  Iteration 0: Cost = 1.0948\n",
            "  Iteration 100: Cost = 1.0948\n",
            "  Iteration 200: Cost = 1.0948\n",
            "  Iteration 300: Cost = 1.0948\n",
            "  Iteration 400: Cost = 1.0948\n",
            "  Iteration 500: Cost = 1.0948\n",
            "  Iteration 600: Cost = 1.0948\n",
            "  Iteration 700: Cost = 1.0948\n",
            "  Iteration 800: Cost = 1.0948\n",
            "  Iteration 900: Cost = 1.0948\n",
            "  Iteration 1000: Cost = 1.0948\n",
            "  Iteration 1100: Cost = 1.0948\n",
            "  Iteration 1200: Cost = 1.0948\n",
            "  Iteration 1300: Cost = 1.0948\n",
            "  Iteration 1400: Cost = 1.0948\n",
            "  Iteration 1500: Cost = 1.0948\n",
            "  Iteration 1600: Cost = 1.0948\n",
            "  Iteration 1700: Cost = 1.0948\n",
            "  Iteration 1800: Cost = 1.0948\n",
            "  Iteration 1900: Cost = 1.0948\n",
            "  Iteration 2000: Cost = 1.0948\n",
            "  Iteration 2100: Cost = 1.0948\n",
            "  Iteration 2200: Cost = 1.0948\n",
            "  Iteration 2300: Cost = 1.0948\n",
            "  Iteration 2400: Cost = 1.0948\n",
            "  Iteration 2500: Cost = 1.0948\n",
            "  Iteration 2600: Cost = 1.0948\n",
            "  Iteration 2700: Cost = 1.0948\n",
            "  Iteration 2800: Cost = 1.0948\n",
            "  Iteration 2900: Cost = 1.0948\n",
            "  Iteration 3000: Cost = 1.0948\n",
            "  Iteration 3100: Cost = 1.0948\n",
            "  Iteration 3200: Cost = 1.0948\n",
            "  Iteration 3300: Cost = 1.0948\n",
            "  Iteration 3400: Cost = 1.0948\n",
            "  Iteration 3500: Cost = 1.0948\n",
            "  Iteration 3600: Cost = 1.0948\n",
            "  Iteration 3700: Cost = 1.0948\n",
            "  Iteration 3800: Cost = 1.0948\n",
            "  Iteration 3900: Cost = 1.0948\n",
            "  Iteration 4000: Cost = 1.0948\n",
            "  Iteration 4100: Cost = 1.0948\n",
            "  Iteration 4200: Cost = 1.0948\n",
            "  Iteration 4300: Cost = 1.0948\n",
            "  Iteration 4400: Cost = 1.0948\n",
            "  Iteration 4500: Cost = 1.0948\n",
            "  Iteration 4600: Cost = 1.0948\n",
            "  Iteration 4700: Cost = 1.0948\n",
            "  Iteration 4800: Cost = 1.0948\n",
            "  Iteration 4900: Cost = 1.0948\n",
            "  Iteration 5000: Cost = 1.0948\n",
            "  Iteration 5100: Cost = 1.0948\n",
            "  Iteration 5200: Cost = 1.0948\n",
            "  Iteration 5300: Cost = 1.0948\n",
            "  Iteration 5400: Cost = 1.0948\n",
            "  Iteration 5500: Cost = 1.0948\n",
            "  Iteration 5600: Cost = 1.0948\n",
            "  Iteration 5700: Cost = 1.0948\n",
            "  Iteration 5800: Cost = 1.0948\n",
            "  Iteration 5900: Cost = 1.0948\n",
            "\n",
            "For 7000 iterations:\n",
            "  Iteration 0: Cost = 1.0948\n",
            "  Iteration 100: Cost = 1.0948\n",
            "  Iteration 200: Cost = 1.0948\n",
            "  Iteration 300: Cost = 1.0948\n",
            "  Iteration 400: Cost = 1.0948\n",
            "  Iteration 500: Cost = 1.0948\n",
            "  Iteration 600: Cost = 1.0948\n",
            "  Iteration 700: Cost = 1.0948\n",
            "  Iteration 800: Cost = 1.0948\n",
            "  Iteration 900: Cost = 1.0948\n",
            "  Iteration 1000: Cost = 1.0948\n",
            "  Iteration 1100: Cost = 1.0948\n",
            "  Iteration 1200: Cost = 1.0948\n",
            "  Iteration 1300: Cost = 1.0948\n",
            "  Iteration 1400: Cost = 1.0948\n",
            "  Iteration 1500: Cost = 1.0948\n",
            "  Iteration 1600: Cost = 1.0948\n",
            "  Iteration 1700: Cost = 1.0948\n",
            "  Iteration 1800: Cost = 1.0948\n",
            "  Iteration 1900: Cost = 1.0948\n",
            "  Iteration 2000: Cost = 1.0948\n",
            "  Iteration 2100: Cost = 1.0948\n",
            "  Iteration 2200: Cost = 1.0948\n",
            "  Iteration 2300: Cost = 1.0948\n",
            "  Iteration 2400: Cost = 1.0948\n",
            "  Iteration 2500: Cost = 1.0948\n",
            "  Iteration 2600: Cost = 1.0948\n",
            "  Iteration 2700: Cost = 1.0948\n",
            "  Iteration 2800: Cost = 1.0948\n",
            "  Iteration 2900: Cost = 1.0948\n",
            "  Iteration 3000: Cost = 1.0948\n",
            "  Iteration 3100: Cost = 1.0948\n",
            "  Iteration 3200: Cost = 1.0948\n",
            "  Iteration 3300: Cost = 1.0948\n",
            "  Iteration 3400: Cost = 1.0948\n",
            "  Iteration 3500: Cost = 1.0948\n",
            "  Iteration 3600: Cost = 1.0948\n",
            "  Iteration 3700: Cost = 1.0948\n",
            "  Iteration 3800: Cost = 1.0948\n",
            "  Iteration 3900: Cost = 1.0948\n",
            "  Iteration 4000: Cost = 1.0948\n",
            "  Iteration 4100: Cost = 1.0948\n",
            "  Iteration 4200: Cost = 1.0948\n",
            "  Iteration 4300: Cost = 1.0948\n",
            "  Iteration 4400: Cost = 1.0948\n",
            "  Iteration 4500: Cost = 1.0948\n",
            "  Iteration 4600: Cost = 1.0948\n",
            "  Iteration 4700: Cost = 1.0948\n",
            "  Iteration 4800: Cost = 1.0948\n",
            "  Iteration 4900: Cost = 1.0948\n",
            "  Iteration 5000: Cost = 1.0948\n",
            "  Iteration 5100: Cost = 1.0948\n",
            "  Iteration 5200: Cost = 1.0948\n",
            "  Iteration 5300: Cost = 1.0948\n",
            "  Iteration 5400: Cost = 1.0948\n",
            "  Iteration 5500: Cost = 1.0948\n",
            "  Iteration 5600: Cost = 1.0948\n",
            "  Iteration 5700: Cost = 1.0948\n",
            "  Iteration 5800: Cost = 1.0948\n",
            "  Iteration 5900: Cost = 1.0948\n",
            "  Iteration 6000: Cost = 1.0948\n",
            "  Iteration 6100: Cost = 1.0948\n",
            "  Iteration 6200: Cost = 1.0948\n",
            "  Iteration 6300: Cost = 1.0948\n",
            "  Iteration 6400: Cost = 1.0948\n",
            "  Iteration 6500: Cost = 1.0948\n",
            "  Iteration 6600: Cost = 1.0948\n",
            "  Iteration 6700: Cost = 1.0948\n",
            "  Iteration 6800: Cost = 1.0948\n",
            "  Iteration 6900: Cost = 1.0948\n",
            "\n",
            "For 8000 iterations:\n",
            "  Iteration 0: Cost = 1.0948\n",
            "  Iteration 100: Cost = 1.0948\n",
            "  Iteration 200: Cost = 1.0948\n",
            "  Iteration 300: Cost = 1.0948\n",
            "  Iteration 400: Cost = 1.0948\n",
            "  Iteration 500: Cost = 1.0948\n",
            "  Iteration 600: Cost = 1.0948\n",
            "  Iteration 700: Cost = 1.0948\n",
            "  Iteration 800: Cost = 1.0948\n",
            "  Iteration 900: Cost = 1.0948\n",
            "  Iteration 1000: Cost = 1.0948\n",
            "  Iteration 1100: Cost = 1.0948\n",
            "  Iteration 1200: Cost = 1.0948\n",
            "  Iteration 1300: Cost = 1.0948\n",
            "  Iteration 1400: Cost = 1.0948\n",
            "  Iteration 1500: Cost = 1.0948\n",
            "  Iteration 1600: Cost = 1.0948\n",
            "  Iteration 1700: Cost = 1.0948\n",
            "  Iteration 1800: Cost = 1.0948\n",
            "  Iteration 1900: Cost = 1.0948\n",
            "  Iteration 2000: Cost = 1.0948\n",
            "  Iteration 2100: Cost = 1.0948\n",
            "  Iteration 2200: Cost = 1.0948\n",
            "  Iteration 2300: Cost = 1.0948\n",
            "  Iteration 2400: Cost = 1.0948\n",
            "  Iteration 2500: Cost = 1.0948\n",
            "  Iteration 2600: Cost = 1.0948\n",
            "  Iteration 2700: Cost = 1.0948\n",
            "  Iteration 2800: Cost = 1.0948\n",
            "  Iteration 2900: Cost = 1.0948\n",
            "  Iteration 3000: Cost = 1.0948\n",
            "  Iteration 3100: Cost = 1.0948\n",
            "  Iteration 3200: Cost = 1.0948\n",
            "  Iteration 3300: Cost = 1.0948\n",
            "  Iteration 3400: Cost = 1.0948\n",
            "  Iteration 3500: Cost = 1.0948\n",
            "  Iteration 3600: Cost = 1.0948\n",
            "  Iteration 3700: Cost = 1.0948\n",
            "  Iteration 3800: Cost = 1.0948\n",
            "  Iteration 3900: Cost = 1.0948\n",
            "  Iteration 4000: Cost = 1.0948\n",
            "  Iteration 4100: Cost = 1.0948\n",
            "  Iteration 4200: Cost = 1.0948\n",
            "  Iteration 4300: Cost = 1.0948\n",
            "  Iteration 4400: Cost = 1.0948\n",
            "  Iteration 4500: Cost = 1.0948\n",
            "  Iteration 4600: Cost = 1.0948\n",
            "  Iteration 4700: Cost = 1.0948\n",
            "  Iteration 4800: Cost = 1.0948\n",
            "  Iteration 4900: Cost = 1.0948\n",
            "  Iteration 5000: Cost = 1.0948\n",
            "  Iteration 5100: Cost = 1.0948\n",
            "  Iteration 5200: Cost = 1.0948\n",
            "  Iteration 5300: Cost = 1.0948\n",
            "  Iteration 5400: Cost = 1.0948\n",
            "  Iteration 5500: Cost = 1.0948\n",
            "  Iteration 5600: Cost = 1.0948\n",
            "  Iteration 5700: Cost = 1.0948\n",
            "  Iteration 5800: Cost = 1.0948\n",
            "  Iteration 5900: Cost = 1.0948\n",
            "  Iteration 6000: Cost = 1.0948\n",
            "  Iteration 6100: Cost = 1.0948\n",
            "  Iteration 6200: Cost = 1.0948\n",
            "  Iteration 6300: Cost = 1.0948\n",
            "  Iteration 6400: Cost = 1.0948\n",
            "  Iteration 6500: Cost = 1.0948\n",
            "  Iteration 6600: Cost = 1.0948\n",
            "  Iteration 6700: Cost = 1.0948\n",
            "  Iteration 6800: Cost = 1.0948\n",
            "  Iteration 6900: Cost = 1.0948\n",
            "  Iteration 7000: Cost = 1.0948\n",
            "  Iteration 7100: Cost = 1.0948\n",
            "  Iteration 7200: Cost = 1.0948\n",
            "  Iteration 7300: Cost = 1.0948\n",
            "  Iteration 7400: Cost = 1.0948\n",
            "  Iteration 7500: Cost = 1.0948\n",
            "  Iteration 7600: Cost = 1.0948\n",
            "  Iteration 7700: Cost = 1.0948\n",
            "  Iteration 7800: Cost = 1.0948\n",
            "  Iteration 7900: Cost = 1.0948\n",
            "\n",
            "For 9000 iterations:\n",
            "  Iteration 0: Cost = 1.0948\n",
            "  Iteration 100: Cost = 1.0948\n",
            "  Iteration 200: Cost = 1.0948\n",
            "  Iteration 300: Cost = 1.0948\n",
            "  Iteration 400: Cost = 1.0948\n",
            "  Iteration 500: Cost = 1.0948\n",
            "  Iteration 600: Cost = 1.0948\n",
            "  Iteration 700: Cost = 1.0948\n",
            "  Iteration 800: Cost = 1.0948\n",
            "  Iteration 900: Cost = 1.0948\n",
            "  Iteration 1000: Cost = 1.0948\n",
            "  Iteration 1100: Cost = 1.0948\n",
            "  Iteration 1200: Cost = 1.0948\n",
            "  Iteration 1300: Cost = 1.0948\n",
            "  Iteration 1400: Cost = 1.0948\n",
            "  Iteration 1500: Cost = 1.0948\n",
            "  Iteration 1600: Cost = 1.0948\n",
            "  Iteration 1700: Cost = 1.0948\n",
            "  Iteration 1800: Cost = 1.0948\n",
            "  Iteration 1900: Cost = 1.0948\n",
            "  Iteration 2000: Cost = 1.0948\n",
            "  Iteration 2100: Cost = 1.0948\n",
            "  Iteration 2200: Cost = 1.0948\n",
            "  Iteration 2300: Cost = 1.0948\n",
            "  Iteration 2400: Cost = 1.0948\n",
            "  Iteration 2500: Cost = 1.0948\n",
            "  Iteration 2600: Cost = 1.0948\n",
            "  Iteration 2700: Cost = 1.0948\n",
            "  Iteration 2800: Cost = 1.0948\n",
            "  Iteration 2900: Cost = 1.0948\n",
            "  Iteration 3000: Cost = 1.0948\n",
            "  Iteration 3100: Cost = 1.0948\n",
            "  Iteration 3200: Cost = 1.0948\n",
            "  Iteration 3300: Cost = 1.0948\n",
            "  Iteration 3400: Cost = 1.0948\n",
            "  Iteration 3500: Cost = 1.0948\n",
            "  Iteration 3600: Cost = 1.0948\n",
            "  Iteration 3700: Cost = 1.0948\n",
            "  Iteration 3800: Cost = 1.0948\n",
            "  Iteration 3900: Cost = 1.0948\n",
            "  Iteration 4000: Cost = 1.0948\n",
            "  Iteration 4100: Cost = 1.0948\n",
            "  Iteration 4200: Cost = 1.0948\n",
            "  Iteration 4300: Cost = 1.0948\n",
            "  Iteration 4400: Cost = 1.0948\n",
            "  Iteration 4500: Cost = 1.0948\n",
            "  Iteration 4600: Cost = 1.0948\n",
            "  Iteration 4700: Cost = 1.0948\n",
            "  Iteration 4800: Cost = 1.0948\n",
            "  Iteration 4900: Cost = 1.0948\n",
            "  Iteration 5000: Cost = 1.0948\n",
            "  Iteration 5100: Cost = 1.0948\n",
            "  Iteration 5200: Cost = 1.0948\n",
            "  Iteration 5300: Cost = 1.0948\n",
            "  Iteration 5400: Cost = 1.0948\n",
            "  Iteration 5500: Cost = 1.0948\n",
            "  Iteration 5600: Cost = 1.0948\n",
            "  Iteration 5700: Cost = 1.0948\n",
            "  Iteration 5800: Cost = 1.0948\n",
            "  Iteration 5900: Cost = 1.0948\n",
            "  Iteration 6000: Cost = 1.0948\n",
            "  Iteration 6100: Cost = 1.0948\n",
            "  Iteration 6200: Cost = 1.0948\n",
            "  Iteration 6300: Cost = 1.0948\n",
            "  Iteration 6400: Cost = 1.0948\n",
            "  Iteration 6500: Cost = 1.0948\n",
            "  Iteration 6600: Cost = 1.0948\n",
            "  Iteration 6700: Cost = 1.0948\n",
            "  Iteration 6800: Cost = 1.0948\n",
            "  Iteration 6900: Cost = 1.0948\n",
            "  Iteration 7000: Cost = 1.0948\n",
            "  Iteration 7100: Cost = 1.0948\n",
            "  Iteration 7200: Cost = 1.0948\n",
            "  Iteration 7300: Cost = 1.0948\n",
            "  Iteration 7400: Cost = 1.0948\n",
            "  Iteration 7500: Cost = 1.0948\n",
            "  Iteration 7600: Cost = 1.0948\n",
            "  Iteration 7700: Cost = 1.0948\n",
            "  Iteration 7800: Cost = 1.0948\n",
            "  Iteration 7900: Cost = 1.0948\n",
            "  Iteration 8000: Cost = 1.0948\n",
            "  Iteration 8100: Cost = 1.0948\n",
            "  Iteration 8200: Cost = 1.0948\n",
            "  Iteration 8300: Cost = 1.0948\n",
            "  Iteration 8400: Cost = 1.0948\n",
            "  Iteration 8500: Cost = 1.0948\n",
            "  Iteration 8600: Cost = 1.0948\n",
            "  Iteration 8700: Cost = 1.0948\n",
            "  Iteration 8800: Cost = 1.0948\n",
            "  Iteration 8900: Cost = 1.0948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        " 200 Iterations\n",
        "-Cost Behavior : The cost starts at 7.0182 and drops to 5.0637 after 100 iterations.\n",
        "-Interpretation : Initial reduction shows progress, but the cost remains high, indicating more optimization is needed.\n",
        "\n",
        "400 Iterations\n",
        "- Cost Behavior : The cost decreases from 3.7541 at iteration 0 to 1.8947 at iteration 300.\n",
        "- Interpretation : Faster improvement, but the rate slows after 100 iterations which shows the model is still optimizing.\n",
        "\n",
        "800 Iterations\n",
        "- Cost Behavior: The cost drops from 1.6307 to 1.1272 at iteration 700.\n",
        "- Interpretation: Slower cost reduction indicates nearing convergence, with fewer improvements per iteration.\n",
        "\n",
        "2000 Iterations\n",
        "-  Cost Behavior : The cost stabilizes at 1.0952 after 1000 iterations.\n",
        "-  Interpretation : The model reaches a plateau, showing minimal improvement with further iterations.\n",
        "\n",
        "5000 Iterations\n",
        "-  Cost Behavior : The cost stays at 1.0948.\n",
        "-  Interpretation : The model has converged, with no significant improvement after many iterations.\n",
        "\n",
        "Conclusion\n",
        "- The model shows rapid improvement in the first few hundred iterations, then stabilizes as it converges.\n",
        "Further training beyond 1000 iterations gives small gains, suggesting that additional iterations aren't much needed.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "u5yhRxvCO0ZJ",
        "outputId": "3697a02e-76c4-4147-8997-a5bdc4ce79a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n 200 Iterations \\n-Cost Behavior : The cost starts at 7.0182 and drops to 5.0637 after 100 iterations.\\n-Interpretation : Initial reduction shows progress, but the cost remains high, indicating more optimization is needed.\\n\\n400 Iterations\\n- Cost Behavior : The cost decreases from 3.7541 at iteration 0 to 1.8947 at iteration 300.\\n- Interpretation : Faster improvement, but the rate slows after 100 iterations, suggesting the model is still optimizing.\\n\\n800 Iterations\\n- Cost Behavior: The cost drops from 1.6307 to 1.1272 at iteration 700.\\n- Interpretation: Slower cost reduction indicates nearing convergence, with fewer improvements per iteration.\\n\\n2000 Iterations \\n-  Cost Behavior : The cost stabilizes at 1.0952 after 1000 iterations.\\n-  Interpretation : The model reaches a plateau, showing minimal improvement with further iterations.\\n\\n5000 Iterations \\n-  Cost Behavior : The cost stays at 1.0948.\\n-  Interpretation : The model has converged, with no significant improvement after many iterations.\\n\\nConclusion \\n- The model shows rapid improvement in the first few hundred iterations, then stabilizes as it converges. \\nFurther training beyond 1000 iterations gives minimal gains, suggesting that additional iterations aren't beneficial.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final weights and biases\n",
        "print(f\"Final weight1:{w1}\")\n",
        "print(f\"Final bias1:\\n{b1}\")\n",
        "print(f\"Final weight2:\\n{w2}\")\n",
        "print(f\"Final bias2:\\n{b2}\")\n",
        "print(f\"Final weight3:\\n{w3}\")\n",
        "print(f\"Final bias3:\\n{b3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_OIru6DBC-P",
        "outputId": "f8db7181-4ee1-4441-9b66-7b3858716de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final weight1:[[ 0.0141256   0.00551461 -0.0150777  -0.00484234  0.02032821]\n",
            " [-0.01638974 -0.00191787  0.00827191 -0.0092693   0.0095872 ]]\n",
            "Final bias1:\n",
            "[[ 0.00018753 -0.00134882 -0.00079552  0.          0.00041813]]\n",
            "Final weight2:\n",
            "[[-0.03191215 -0.01024388 -0.00252987 -0.01247784  0.01632187]\n",
            " [-0.01068308 -0.00440044  0.00130211  0.01441228 -0.01436002]\n",
            " [ 0.01186759  0.00010233 -0.0098151   0.00462051  0.0019906 ]\n",
            " [-0.00600217  0.00069802 -0.00385314  0.00113517  0.00662131]\n",
            " [ 0.02442133 -0.01237815  0.02132093 -0.01952094 -0.00151933]]\n",
            "Final bias2:\n",
            "[[ 2.73300774e-02  0.00000000e+00 -6.01991999e-04 -9.78473158e-05\n",
            "  -1.42437482e-04]]\n",
            "Final weight3:\n",
            "[[ 0.03176745]\n",
            " [ 0.00280992]\n",
            " [-0.00622416]\n",
            " [-0.0020798 ]\n",
            " [-0.00492908]]\n",
            "Final bias3:\n",
            "[[2.43292377]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xtmbr00NYBKN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}